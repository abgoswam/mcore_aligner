/home/aiscuser/mcore_aligner/scripts_python
/usr/lib/python310.zip
/usr/lib/python3.10
/usr/lib/python3.10/lib-dynload
/home/aiscuser/.local/lib/python3.10/site-packages
/usr/local/lib/python3.10/dist-packages
/usr/local/lib/python3.10/dist-packages/nvfuser-0.2.3a0+f73ff1b-py3.10-linux-x86_64.egg
/usr/local/lib/python3.10/dist-packages/lightning_thunder-0.2.0.dev0-py3.10.egg
/usr/local/lib/python3.10/dist-packages/opt_einsum-3.3.0-py3.10.egg
/usr/local/lib/python3.10/dist-packages/igraph-0.11.5-py3.10-linux-x86_64.egg
/usr/local/lib/python3.10/dist-packages/lightning_utilities-0.11.2-py3.10.egg
/usr/local/lib/python3.10/dist-packages/looseversion-1.3.0-py3.10.egg
/usr/local/lib/python3.10/dist-packages/texttable-1.7.0-py3.10.egg
/usr/lib/python3/dist-packages
/home/aiscuser/mcore_aligner/MSFT-Megatron-LM-10262024
Layer: embedding.word_embeddings.weight, Size: (32000, 4096)
Layer: decoder.layers.0.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.0.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.0.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.0.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.0.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.0.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.1.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.1.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.1.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.1.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.1.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.1.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.2.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.2.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.2.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.2.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.2.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.2.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.3.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.3.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.3.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.3.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.3.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.3.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.4.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.4.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.4.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.4.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.4.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.4.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.5.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.5.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.5.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.5.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.5.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.5.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.6.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.6.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.6.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.6.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.6.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.6.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.7.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.7.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.7.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.7.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.7.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.7.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.8.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.8.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.8.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.8.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.8.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.8.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.9.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.9.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.9.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.9.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.9.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.9.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.10.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.10.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.10.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.10.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.10.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.10.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.11.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.11.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.11.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.11.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.11.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.11.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.12.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.12.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.12.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.12.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.12.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.12.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.13.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.13.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.13.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.13.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.13.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.13.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.14.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.14.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.14.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.14.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.14.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.14.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.15.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.15.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.15.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.15.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.15.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.15.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.16.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.16.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.16.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.16.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.16.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.16.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.17.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.17.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.17.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.17.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.17.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.17.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.18.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.18.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.18.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.18.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.18.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.18.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.19.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.19.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.19.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.19.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.19.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.19.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.20.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.20.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.20.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.20.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.20.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.20.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.21.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.21.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.21.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.21.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.21.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.21.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.22.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.22.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.22.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.22.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.22.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.22.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.23.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.23.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.23.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.23.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.23.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.23.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.24.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.24.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.24.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.24.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.24.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.24.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.25.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.25.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.25.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.25.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.25.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.25.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.26.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.26.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.26.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.26.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.26.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.26.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.27.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.27.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.27.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.27.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.27.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.27.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.28.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.28.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.28.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.28.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.28.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.28.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.29.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.29.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.29.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.29.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.29.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.29.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.30.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.30.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.30.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.30.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.30.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.30.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.layers.31.self_attention.linear_proj.weight, Size: (4096, 4096)
Layer: decoder.layers.31.self_attention.linear_qkv.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.31.self_attention.linear_qkv.weight, Size: (6144, 4096)
Layer: decoder.layers.31.mlp.linear_fc1.layer_norm_weight, Size: (4096,)
Layer: decoder.layers.31.mlp.linear_fc1.weight, Size: (28672, 4096)
Layer: decoder.layers.31.mlp.linear_fc2.weight, Size: (4096, 14336)
Layer: decoder.final_layernorm.weight, Size: (4096,)
Layer: output_layer.weight, Size: (32000, 4096)
